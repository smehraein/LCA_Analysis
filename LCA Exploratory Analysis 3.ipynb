{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCA Exploratory Analysis 3 - Who's being rejected and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this last section, I want to take a look at the applicants who have their LCAs rejected. Note that these aren't full H1B applications - the LCA is only one step in the process. The overwhelming majority of these are approved, so I'm curious to see if there's a pattern to those applications which are rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "f = open(\"Delta_LCA.csv\", \"r\")\n",
    "delta_df = pd.read_csv(f, index_col=0)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certified Applications: 472803\n",
      "Denied Applications: 10982\n",
      "Percent Denied Applications: 2.27\n"
     ]
    }
   ],
   "source": [
    "# I'm only interested in CERTIFIED and DENIED applications here, so let's filter for those.\n",
    "\n",
    "certified_delta_df = delta_df[delta_df.STATUS.str.contains(\"CERTIFIED\")]\n",
    "denied_delta_df = delta_df[delta_df.STATUS == \"DENIED\"]\n",
    "cd_delta_df = delta_df[delta_df.STATUS != \"WITHDRAWN\"]  # I'm not counting WITHDRAWN apps.\n",
    "cd_delta_df = cd_delta_df.replace(\"CERTIFIED-WITHDRAWN\", \"CERTIFIED\")  # I'll count apps that were withdrawn post-fact.\n",
    "total_applications = float(len(cd_delta_df))\n",
    "\n",
    "print \"Certified Applications:\", len(certified_delta_df)\n",
    "print \"Denied Applications:\", len(denied_delta_df)\n",
    "print \"Percent Denied Applications:\", round(100 * len(denied_delta_df)/total_applications, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at large companies and see if any particular group of them tend to get denied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BETA SOFT SYSTEMS INC                         0.202830\n",
      "ERNST & YOUNG US LLP                          0.050492\n",
      "CHARTER GLOBAL INC                            0.045614\n",
      "PHOTON INFOTECH INC                           0.044379\n",
      "MOTOROLA MOBILITY LLC                         0.042493\n",
      "HARVARD UNIVERSITY                            0.041509\n",
      "IBM INDIA PRIVATE LTD                         0.038636\n",
      "ECLINICALWORKS LLC                            0.038596\n",
      "CAPGEMINI US LLC                              0.035539\n",
      "MASTECH INC A MASTECH HOLDINGS INC COMPANY    0.033226\n",
      "Name: Denied_prop, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grouped_by_company = cd_delta_df.groupby([\"LCA_CASE_EMPLOYER_NAME\"])\n",
    "valid_companies = grouped_by_company.size()[grouped_by_company.size() > 250].keys()\n",
    "\n",
    "denied_company_df = denied_delta_df[cd_delta_df[\"LCA_CASE_EMPLOYER_NAME\"].isin(valid_companies)]\n",
    "certified_company_df = certified_delta_df[cd_delta_df[\"LCA_CASE_EMPLOYER_NAME\"].isin(valid_companies)]\n",
    "d_grouped_by_company = denied_company_df.groupby(\"LCA_CASE_EMPLOYER_NAME\").size()\n",
    "c_grouped_by_company = certified_company_df.groupby(\"LCA_CASE_EMPLOYER_NAME\").size()\n",
    "\n",
    "# I'm going to perform a join on these two series to calculate the percent denied for companies.\n",
    "# There has got to be a better way to do this - I'd love to know how.\n",
    "\n",
    "company_df = pd.concat([c_grouped_by_company, d_grouped_by_company], axis=1)\n",
    "\n",
    "company_df[\"Denied_prop\"] = company_df[1]/company_df[0]\n",
    "\n",
    "print company_df[\"Denied_prop\"].dropna().order(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there's one huge outlier. After looking them up, I found a lot of negative reviews for \"Beta Soft Systems Inc\" which lead me to be very suspicious of this company. Other than that, there isn't anything particularly interesting here. Perhaps sorting by state will show something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE\n",
      "PR    0.153374\n",
      "WY    0.142857\n",
      "GU    0.122222\n",
      "HI    0.070850\n",
      "MS    0.068441\n",
      "VI    0.066667\n",
      "NM    0.064935\n",
      "LA    0.049834\n",
      "NV    0.047750\n",
      "MT    0.041667\n",
      "AL    0.038613\n",
      "DC    0.038473\n",
      "FL    0.037617\n",
      "ID    0.035556\n",
      "NY    0.034625\n",
      "ND    0.034091\n",
      "OK    0.032602\n",
      "WV    0.031746\n",
      "NE    0.030060\n",
      "AK    0.029851\n",
      "SD    0.028708\n",
      "UT    0.028137\n",
      "KY    0.027778\n",
      "CO    0.027518\n",
      "VT    0.026936\n",
      "KS    0.026740\n",
      "MA    0.025701\n",
      "MD    0.025632\n",
      "SC    0.024103\n",
      "OH    0.022504\n",
      "CA    0.022419\n",
      "VA    0.022205\n",
      "TX    0.021772\n",
      "MI    0.021329\n",
      "MO    0.020059\n",
      "AR    0.020010\n",
      "PA    0.019983\n",
      "OR    0.019776\n",
      "NC    0.019659\n",
      "MN    0.019319\n",
      "IL    0.018739\n",
      "AZ    0.017998\n",
      "GA    0.017992\n",
      "NJ    0.017514\n",
      "TN    0.016699\n",
      "WI    0.016657\n",
      "CT    0.016462\n",
      "WA    0.016457\n",
      "IN    0.015867\n",
      "ME    0.014634\n",
      "IA    0.014373\n",
      "NH    0.014276\n",
      "RI    0.013276\n",
      "DE    0.011584\n",
      "Name: Denied_prop, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "d_grouped_by_state = denied_delta_df.groupby(\"STATE\").size()\n",
    "c_grouped_by_state = certified_delta_df.groupby(\"STATE\").size()\n",
    "\n",
    "state_df = pd.concat([c_grouped_by_state, d_grouped_by_state], axis=1)\n",
    "\n",
    "state_df[\"Denied_prop\"] = state_df[1]/state_df[0]\n",
    "\n",
    "print state_df[\"Denied_prop\"].dropna().order(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, Puerto Rico, Wyoming, and Guam are standouts, but otherwise nothing interesting here. Let's keep going and look at industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCA_CASE_NAICS_CODE\n",
      "54111    0.208589\n",
      "5411     0.200000\n",
      "53131    0.156716\n",
      "5412     0.146789\n",
      "6111     0.145833\n",
      "Name: Denied_prop, dtype: float64\n",
      "LCA_CASE_NAICS_CODE\n",
      "334400    0.004292\n",
      "51121     0.004176\n",
      "452112    0.003831\n",
      "3336      0.002660\n",
      "334290    0.002392\n",
      "Name: Denied_prop, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grouped_by_ind = cd_delta_df.groupby([\"LCA_CASE_NAICS_CODE\"])\n",
    "valid_industries = grouped_by_ind.size()[grouped_by_ind.size() > 100].keys()\n",
    "\n",
    "denied_ind_df = denied_delta_df[cd_delta_df[\"LCA_CASE_NAICS_CODE\"].isin(valid_industries)]\n",
    "certified_ind_df = certified_delta_df[cd_delta_df[\"LCA_CASE_NAICS_CODE\"].isin(valid_industries)]\n",
    "d_grouped_by_ind = denied_ind_df.groupby(\"LCA_CASE_NAICS_CODE\").size()\n",
    "c_grouped_by_ind = certified_ind_df.groupby(\"LCA_CASE_NAICS_CODE\").size()\n",
    "\n",
    "ind_df = pd.concat([c_grouped_by_ind, d_grouped_by_ind], axis=1)\n",
    "\n",
    "ind_df[\"Denied_prop\"] = ind_df[1]/ind_df[0]\n",
    "\n",
    "print ind_df[\"Denied_prop\"].dropna().order(ascending=False).head()\n",
    "print ind_df[\"Denied_prop\"].dropna().order(ascending=False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, \"Offices of Lawyers\" and \" Legal Services\" seem to have the wost luck getting certified, while manufacturing industries such as \" Engine, Turbine, and Power Transmission Equipment Manufacturing\" and \"Other Communications Equipment Manufacturing\" are very safe. Perhaps there are specific jobs related to these industries that can tell me more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media and Communication Workers, All Other    0.291391\n",
      "Film and Video Editors                        0.273810\n",
      "Chefs and Head Cooks                          0.231579\n",
      "Designers, All Other                          0.206667\n",
      "Administrative Services Managers              0.183206\n",
      "Name: Denied_prop, dtype: float64\n",
      "Marine Engineers and Naval Architects    0.012712\n",
      "Computer Systems Analysts                0.011984\n",
      "Computer Hardware Engineers              0.011331\n",
      "Computer Occupations, All Other          0.010892\n",
      "Postsecondary Teachers, All Other        0.006173\n",
      "Name: Denied_prop, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grouped_by_job = cd_delta_df.groupby([\"LCA_CASE_SOC_NAME\"])\n",
    "valid_jobs = grouped_by_job.size()[grouped_by_job.size() > 100].keys()\n",
    "\n",
    "denied_job_df = denied_delta_df[cd_delta_df[\"LCA_CASE_SOC_NAME\"].isin(valid_jobs)]\n",
    "certified_job_df = certified_delta_df[cd_delta_df[\"LCA_CASE_SOC_NAME\"].isin(valid_jobs)]\n",
    "d_grouped_by_job = denied_job_df.groupby(\"LCA_CASE_SOC_NAME\").size()\n",
    "c_grouped_by_job = certified_job_df.groupby(\"LCA_CASE_SOC_NAME\").size()\n",
    "\n",
    "job_df = pd.concat([c_grouped_by_job, d_grouped_by_job], axis=1)\n",
    "\n",
    "job_df[\"Denied_prop\"] = job_df[1]/job_df[0]\n",
    "\n",
    "print job_df[\"Denied_prop\"].dropna().order(ascending=False).head()\n",
    "print job_df[\"Denied_prop\"].dropna().order(ascending=False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those in media, design, and administration are most likely to be rejected, while applicants in tech and engineering fields, along with postsecondary teachers (read: university employees) don't have much of a problem. I'm not surpirsed that the engineering and univeristy workers don't have much trouble, though the jobs that are least likely to be certified don't match the industry with the most trouble (Law).\n",
    "\n",
    "Let's look at part time vs. full time next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL_TIME_POS\n",
      "N    0.049389\n",
      "Y    0.021189\n",
      "Name: Denied_prop, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "d_grouped_by_time = denied_job_df.groupby(\"FULL_TIME_POS\").size()\n",
    "c_grouped_by_time = certified_job_df.groupby(\"FULL_TIME_POS\").size()\n",
    "\n",
    "time_df = pd.concat([c_grouped_by_time, d_grouped_by_time], axis=1)\n",
    "\n",
    "time_df[\"Denied_prop\"] = time_df[1]/time_df[0]\n",
    "\n",
    "print time_df[\"Denied_prop\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those who aren't working full time are more than twice as likely to be denied. Let's keep digging and examine wages and units of pay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Annual Certified Wage: 70013.45\n",
      "Average Annual Denied Wage: 67187.47\n",
      "Average Hourly Certified Wage: 30.78\n",
      "Average Hourly Denied Wage: 27.08\n",
      "Prop Salaried Workers Denied: 0.02\n",
      "Prop Hourly Workers Denied: 0.052\n"
     ]
    }
   ],
   "source": [
    "c_year_df = certified_delta_df[certified_delta_df[\"PW_UNIT_1\"] == \"Year\"]\n",
    "d_year_df = denied_delta_df[denied_delta_df[\"PW_UNIT_1\"] == \"Year\"]\n",
    "\n",
    "c_hour_df = certified_delta_df[certified_delta_df[\"PW_UNIT_1\"] == \"Hour\"]\n",
    "d_hour_df = denied_delta_df[denied_delta_df[\"PW_UNIT_1\"] == \"Hour\"]\n",
    "\n",
    "print \"Average Annual Certified Wage:\", round(c_year_df[\"PW_1\"].mean(), 2)\n",
    "print \"Average Annual Denied Wage:\", round(d_year_df[\"PW_1\"].mean(), 2)\n",
    "\n",
    "print \"Average Hourly Certified Wage:\", round(c_hour_df[\"PW_1\"].mean(), 2)\n",
    "print \"Average Hourly Denied Wage:\", round(d_hour_df[\"PW_1\"].mean(), 2)\n",
    "\n",
    "print \"Prop Salaried Workers Denied:\", round(len(d_year_df)/float(len(d_year_df)+len(c_year_df)), 3)\n",
    "print \"Prop Hourly Workers Denied:\", round(len(d_hour_df)/float(len(d_hour_df)+len(c_hour_df)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense. Not only are denied applicants likely to make less, those who work hourly are much more likely to be denied. This goes hand in hand with the previous observation that applicants who aren't working full time are most likely to be denied. The prevailing pattern seems to be that working full time with an annual salary provides the best odds of being certified."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

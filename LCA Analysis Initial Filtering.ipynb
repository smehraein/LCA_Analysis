{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Filtering - Extract from .xlsx, filter, and write to .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a massive amount of data in this .xlsx file (over 500,000 rows). It contains all LCA requests from the year 2014. My first goal is to extract it from Excel format, drop rows and columns that I won't need, and write it to a csv for easier access.\n",
    "\n",
    "I originally planned to use the past 3 years of data, but that was simply too much for my 13\" Mac to handle. :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading\n",
      "Done Reading\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f = open(\"2014_LCA.xlsx\", \"r\")\n",
    "\n",
    "print \"Reading\"  # This takes a while...\n",
    "raw_df = pd.read_excel(f)\n",
    "print \"Done Reading\"\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the associated .doc file, I can determine which columns aren't going to be valuable for the analysis I have planned:\n",
    "\n",
    "\"VISA_CLASS\" - These are all H1B  \n",
    "\"PW_SOURCE_1\" - Wage source info  \n",
    "\"OTHER_WAGE_SOURCE_1\" - Wage source info  \n",
    "\"YR_SOURCE_PUB_1\" - Wage source info  \n",
    "\"PW_UNIT_2\"  \n",
    "\"PW_SOURCE_2\"  \n",
    "\"OTHER_WAGE_SOURCE_2\"  \n",
    "\"YR_SOURCE_PUB_2\"  \n",
    "\n",
    "In addition, let's check the number of null values in each column to see if there are any very sparse columns to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCA_CASE_NUMBER                        0\n",
      "STATUS                                 0\n",
      "LCA_CASE_SUBMIT                        0\n",
      "DECISION_DATE                          0\n",
      "VISA_CLASS                             0\n",
      "LCA_CASE_EMPLOYMENT_START_DATE         4\n",
      "LCA_CASE_EMPLOYMENT_END_DATE           5\n",
      "LCA_CASE_EMPLOYER_NAME                28\n",
      "LCA_CASE_EMPLOYER_ADDRESS             42\n",
      "LCA_CASE_EMPLOYER_CITY                27\n",
      "LCA_CASE_EMPLOYER_STATE               46\n",
      "LCA_CASE_EMPLOYER_POSTAL_CODE         41\n",
      "LCA_CASE_SOC_CODE                     49\n",
      "LCA_CASE_SOC_NAME                   4271\n",
      "LCA_CASE_JOB_TITLE                     7\n",
      "LCA_CASE_WAGE_RATE_FROM               36\n",
      "LCA_CASE_WAGE_RATE_TO             416572\n",
      "LCA_CASE_WAGE_RATE_UNIT               36\n",
      "FULL_TIME_POS                          5\n",
      "TOTAL_WORKERS                          3\n",
      "LCA_CASE_WORKLOC1_CITY                49\n",
      "LCA_CASE_WORKLOC1_STATE               49\n",
      "PW_1                                  84\n",
      "PW_UNIT_1                             77\n",
      "PW_SOURCE_1                           80\n",
      "OTHER_WAGE_SOURCE_1                11413\n",
      "YR_SOURCE_PUB_1                       84\n",
      "LCA_CASE_WORKLOC2_CITY            435616\n",
      "LCA_CASE_WORKLOC2_STATE           435598\n",
      "PW_2                              435595\n",
      "PW_UNIT_2                         435594\n",
      "PW_SOURCE_2                       435596\n",
      "OTHER_WAGE_SOURCE_2               436810\n",
      "YR_SOURCE_PUB_2                   436810\n",
      "LCA_CASE_NAICS_CODE                   25\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print raw_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the second work place and WAGE_RATE_TO columns are too sparse to work with, so I'll drop those. The full list of columns to drop is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unwanted_columns = [\"VISA_CLASS\", \"LCA_CASE_WAGE_RATE_TO\", \"PW_SOURCE_1\", \"OTHER_WAGE_SOURCE_1\", \"YR_SOURCE_PUB_1\", \n",
    "                    \"LCA_CASE_WORKLOC2_CITY\", \"LCA_CASE_WORKLOC2_CITY\", \"LCA_CASE_WORKLOC2_STATE\", \n",
    "                    \"PW_2\", \"PW_UNIT_2\", \"PW_SOURCE_2\",\"OTHER_WAGE_SOURCE_2\", \"YR_SOURCE_PUB_2\"]\n",
    "\n",
    "raw_df = raw_df.drop(unwanted_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LCA_CASE_SOC_NAME column is missing plenty of items, but is directly linked to the SOC_CODE column preceding it, so I can probably fill in most of the missing values by comparing rows with the same SOC_CODE. Let's get a list of the codes for these missing names, then print out the values associated with those codes. As long as there's a non-null value associated with a code, I can fill in the other rows it appears in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "soc_null_codes = raw_df.LCA_CASE_SOC_CODE[raw_df.LCA_CASE_SOC_NAME.isnull()].unique()\n",
    "\n",
    "code_name_list = []\n",
    "\n",
    "for code in soc_null_codes:\n",
    "    names = raw_df.LCA_CASE_SOC_NAME[raw_df.LCA_CASE_SOC_CODE == code].unique()\n",
    "    if len(names) > 1: # If there's something other than NaN here...\n",
    "        code_name_list.append([code, names])\n",
    "\n",
    "print code_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, so much for that. I'll use dropna() to remove rows with any null values. The biggest hit will come from dropping these rows with no SOC_NAME, but we have 500,000+ data points and this represents less than 10% of the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_df = raw_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I need to clean up the EMPLOYER_NAME column. I later found that many rows were being mis-grouped due to this (ex. \"GOOGLE, INC.\" and \"GOOGLE  INC.\" would count as separate employers). I'll try to go about doing this by first grouping the rows by EMPLOYER_ADDRESS and EMPLOYER_POSTAL_CODE, then standardizing the names in all of those groups (the assumption being that there is only one company per street address per zip code).\n",
    "\n",
    "However, I first need to clean up the POSTAL_CODE column. In most cases, the value is a standard 5 number ZIP code, but there are some full 9-digit ones that should be truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCA_CASE_EMPLOYER_ADDRESS                         LCA_CASE_EMPLOYER_POSTAL_CODE\n",
      "#1 CHILDREN'S WAY                                 72202                              1\n",
      "#1 HIGHLANDER WAY                                 33853                              1\n",
      "#1 SMOKY VALLEY MINE ROAD                         89045                              2\n",
      "#16-529 WEST 48TH ST                              10019                              1\n",
      "#2 JOHN BREWERS BAY                               00802                              3\n",
      "#2 SAINT ANTHONY'S WAY                            62002                              1\n",
      "#202, 5609 COLLEGE AVE                            94618                              2\n",
      "#233, 75 BROADWAY                                 94111                             22\n",
      "#3 NATURAL RESOURCES DRIVE                        72215                              3\n",
      "#3 RESEARCH PARK DRIVE                            63304                              1\n",
      "#48 PR STATE ROAD 165 KM 1.2                      00968                              1\n",
      "#5 STATEHOUSE PLAZA, SUITE 500                    72201                              1\n",
      "#50 COUNTY ROAD 13                                87013                              1\n",
      "#6 CITYPLACE DRIVE                                63141                              2\n",
      "#6, ROCK ISLAND                                   73401                              2\n",
      "% DAVID MILLER                                    40204                              1\n",
      "*HQ, THE LANDMARK @ ONE MARKET STREET, SUITE 300  94105                              2\n",
      "0-44 SADDLE RIVER ROAD                            07410                              1\n",
      "02 WEST 45TH STREET                               10036                              1\n",
      "025 SW SHERMAN STREET                             97201                              2\n",
      "0615 SW PALATINE HILL ROAD                        97219                              1\n",
      "1 AARONSON DRIVE                                  21061                              4\n",
      "1 AAVID CIRCLE                                    03246                              5\n",
      "1 ADP BOULEVARD                                   07068                             31\n",
      "1 AGRAND STREET                                   01607                              1\n",
      "1 AIRPORT PLACE, SUITE 3                          08540                              1\n",
      "1 AKRON GENERAL AVENUE                            44307                              2\n",
      "1 ALBERTSON AVE                                   11507                              4\n",
      "1 ALEWIFE CENTER SUITE 200                        02140                              1\n",
      "1 ALEXANDER PLACE                                 11542                              7\n",
      "                                                                                  ... \n",
      "WOODBRIDGE CORPORATE PLAZA                        08830                              4\n",
      "WOODLAND ROAD                                     15232                              1\n",
      "WOODMEN TOWER                                     68102                              3\n",
      "WORLD TRADE CENTER EAST                           02210                              1\n",
      "WORLDWIDE PLAZA 309  WEST 49TH STREET             10019                              1\n",
      "WORLDWIDE PLAZA 309 WEST  49TH STREET             10019                              1\n",
      "WORLDWIDE PLAZA 309 WEST 49TH STREET              10019                             98\n",
      "                                                  10041                              1\n",
      "                                                  10281                              3\n",
      "WORLDWIDE PLAZA 309 WET 49TH STREET               10019                              1\n",
      "WORLDWIDE PLAZA, 309 WEST 49TH STREET             10019                              3\n",
      "WORLDWIDE PLAZA,309 WEST 49TH STREET              10019                              1\n",
      "YALE  UNIVERSITY  / OISS                          06520                              1\n",
      "YALE  UNIVERSITY / OISS                           06520                              1\n",
      "YALE  UNIVERSITY/ OISS                            06520                              6\n",
      "YALE UNIVERSITY                                   06520                              1\n",
      "YALE UNIVERSITY  / OISS                           06520                              2\n",
      "YALE UNIVERSITY / OISS                            06520                             19\n",
      "YALE UNIVERSITY OISS                              06520                              7\n",
      "YALE UNIVERSITY, OISS                             06520                              2\n",
      "YALE UNIVERSITY/  OISS                            06520                              2\n",
      "YALE UNIVERSITY/ O ISS                            06520                              1\n",
      "YALE UNIVERSITY/ OISS                             06520                             66\n",
      "                                                  06525                              1\n",
      "                                                  0T652                              1\n",
      "YALE UNIVERSITY/OISS                              05620                              1\n",
      "                                                  06510                              1\n",
      "                                                  06520                            107\n",
      "YMCA BUILDING  ROOM 101A                          77843                              1\n",
      "ZACHARY TAYLOR CIRCLE                             20171                              1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "raw_df[\"LCA_CASE_EMPLOYER_POSTAL_CODE\"] = [str(t)[:5] for t in raw_df[\"LCA_CASE_EMPLOYER_POSTAL_CODE\"]]\n",
    "\n",
    "grouped_by_location = raw_df.groupby([\"LCA_CASE_EMPLOYER_ADDRESS\", \"LCA_CASE_EMPLOYER_POSTAL_CODE\"])\n",
    "\n",
    "print grouped_by_location.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, Yale seems to have proven that the street addresses and the ZIP codes are just as error prone as the company names (you can find a zip code with a letter in it, if you look hard enough). I'll go for the low-hanging fruit and deformat the EMPLOYER_NAME column for now. This should fix most of the issues with name mis-matches, but the key thing going forward will be to use functions such as .contains() rather than exact matches to perform searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_df[\"LCA_CASE_EMPLOYER_NAME\"] = raw_df[\"LCA_CASE_EMPLOYER_NAME\"].str.replace(\",\", \"\")  # remove \",\"\n",
    "raw_df[\"LCA_CASE_EMPLOYER_NAME\"] = raw_df[\"LCA_CASE_EMPLOYER_NAME\"].str.replace(\".\", \"\")  # remove \".\"\n",
    "raw_df[\"LCA_CASE_EMPLOYER_NAME\"] = raw_df[\"LCA_CASE_EMPLOYER_NAME\"].str.replace(\" - \", \"-\")  # remove whitespace\n",
    "raw_df[\"LCA_CASE_EMPLOYER_NAME\"] = raw_df[\"LCA_CASE_EMPLOYER_NAME\"].str.replace(\"  \", \" \")  # remove double spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to fix the ZIP Codes by removing values that aren't digits. There are also a few ZIP codes less than 00501 (the lowest ZIP in the country). I could search for the correct code, but in the intrest of time I'll just drop them (it's only a few rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postcode = \"LCA_CASE_EMPLOYER_POSTAL_CODE\"\n",
    "\n",
    "raw_df = raw_df[raw_df[postcode].astype(str).str.isdigit()]  # remove rows with invalid ZIP\n",
    "raw_df[postcode] = raw_df[postcode].astype(int)  # convert to int\n",
    "raw_df = raw_df[raw_df[postcode] > 500]  # remove rows with invalid ZIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check the STATUS column. This is one of the most important columns, displaying the status of each LCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS\n",
      "CERTIFIED              451336\n",
      "CERTIFIED-WITHDRAWN     36008\n",
      "DENIED                  11765\n",
      "INVALIDATED                 1\n",
      "REJECTED                    2\n",
      "WITHDRAWN               15869\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "grouped_by_status = raw_df.groupby(\"STATUS\")\n",
    "\n",
    "print grouped_by_status.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure whether INVALIDATED means WITHDRAWN or DENIED, so I'll drop that row (it's only 1 row). REJECTED should clearly be DENIED, however.\n",
    "\n",
    "I originally wanted to drop all the WITHDRAWN rows because they don't provide information about whether or not an LCA was approved, but I ultimately decided to keep them to better understand which companies and industries are applying for LCAs in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_df = raw_df[raw_df.STATUS != \"INVALIDATED\"]\n",
    "raw_df = raw_df.replace(\"REJECTED\", \"DENIED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a last look at all the numeric columns and see if there are any values which are clearly wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LCA_CASE_EMPLOYER_POSTAL_CODE  LCA_CASE_WAGE_RATE_FROM  TOTAL_WORKERS  \\\n",
      "count                  514980.000000             5.149800e+05  514980.000000   \n",
      "mean                    47607.148891             9.244402e+04       1.956802   \n",
      "std                     33621.774342             1.021886e+07       5.867502   \n",
      "min                       550.000000             7.010000e+00       1.000000   \n",
      "25%                     12009.000000             6.000000e+04       1.000000   \n",
      "50%                     45458.000000             7.000000e+04       1.000000   \n",
      "75%                     77056.000000             9.000000e+04       1.000000   \n",
      "max                     99919.000000             7.278873e+09    2013.000000   \n",
      "\n",
      "               PW_1  LCA_CASE_NAICS_CODE  \n",
      "count  5.149800e+05         5.149800e+05  \n",
      "mean   6.977412e+04         4.725347e+05  \n",
      "std    1.542606e+06         1.611078e+06  \n",
      "min    0.000000e+00         1.100000e+01  \n",
      "25%    5.222900e+04         5.182100e+05  \n",
      "50%    6.333600e+04         5.415110e+05  \n",
      "75%    7.976350e+04         5.415110e+05  \n",
      "max    8.201323e+08         8.129908e+08  \n"
     ]
    }
   ],
   "source": [
    "print raw_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, there are errors in the TOTAL_WORKERS and PW_1 columns. There is a row requesting 2013 total workers (a misplaced date, most likely) and a row claiming a wage of $0.00. I'll drop these and take another look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LCA_CASE_EMPLOYER_POSTAL_CODE  LCA_CASE_WAGE_RATE_FROM  TOTAL_WORKERS  \\\n",
      "count                  514977.000000             5.149770e+05  514977.000000   \n",
      "mean                    47607.127252             9.244424e+04       1.952901   \n",
      "std                     33621.802222             1.021889e+07       5.155036   \n",
      "min                       550.000000             7.010000e+00       1.000000   \n",
      "25%                     12009.000000             6.000000e+04       1.000000   \n",
      "50%                     45458.000000             7.000000e+04       1.000000   \n",
      "75%                     77056.000000             9.000000e+04       1.000000   \n",
      "max                     99919.000000             7.278873e+09     200.000000   \n",
      "\n",
      "               PW_1  LCA_CASE_NAICS_CODE  \n",
      "count  5.149770e+05         5.149770e+05  \n",
      "mean   6.977443e+04         4.725361e+05  \n",
      "std    1.542610e+06         1.611082e+06  \n",
      "min    7.010000e+00         1.100000e+01  \n",
      "25%    5.222900e+04         5.182100e+05  \n",
      "50%    6.333600e+04         5.415110e+05  \n",
      "75%    7.976500e+04         5.415110e+05  \n",
      "max    8.201323e+08         8.129908e+08  \n"
     ]
    }
   ],
   "source": [
    "raw_df = raw_df[raw_df.PW_1 != 0]\n",
    "raw_df = raw_df[raw_df.TOTAL_WORKERS != 2013]\n",
    "\n",
    "print raw_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PW_1 (Prevailing Wage Rate) column looks fine now, but there's still a value of 200 in TOTAL_WORKERS. Since the 75% of that column is still 1, it's clearly an outlier - let's take a look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ORACLE AMERICA INC' u'SYNTEL CONSULTING INC' u'SYNTEL INC'\n",
      " u'ITELLIGENCE INC' u'CFA INSTITUTE' u'SYNOPSYS INC'\n",
      " u'IGATE TECHNOLOGIES INC' u'AMAZON CORPORATE LLC'\n",
      " u'QUALCOMM TECHNOLOGIES INC' u'WIPRO LIMITED'\n",
      " u'TATA CONSULTANCY SERVICES LIMITED' u'APPLE INC' u'ACCENTURE LLP'\n",
      " u'AMIRIT TECHNOLOGIES INC' u'RVS LINE LLC' u'BILINGUALS INC'\n",
      " u'JUNIPER NETWORKS (US) INC' u'JUNIPER NETWORKS INC'\n",
      " u'PRICEWATERHOUSECOOPERS LLP' u'NIIT TECHNOLOGIES LIMITED'\n",
      " u'PRICEWATERHOUSECOOPERS ADVISORY LLC' u'DETROIT EDUCATION & RESEARCH'\n",
      " u'CAYLEY AEROSPACE INC' u'PROGRAMMER RESOURCES INTERNATIONAL INC'\n",
      " u'PRESENCE SAINT FRANCIS HOSPITAL' u'WILLIAM BEAUMONT HOSPITAL'\n",
      " u'PRESENCE SAINT JOSEPH HOSPITAL-CHICAGO'\n",
      " u'SPRINGLEAF GENERAL SERVICES CORPORATION']\n"
     ]
    }
   ],
   "source": [
    "print str(raw_df[\"LCA_CASE_EMPLOYER_NAME\"][raw_df.TOTAL_WORKERS > 50].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there's actually several companies requesting more than 50 workers at a time. Let's look at Oracle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique TOTAL_WORKERS values from Oracle: [   1.  100.   10.    4.    5.   20.]\n",
      "Total applications from Oracle: 1073\n",
      "Total applications from Oracle where TOTAL_WORKERS == 20: 25\n",
      "Total applications from Oracle where TOTAL_WORKERS == 100: 1\n"
     ]
    }
   ],
   "source": [
    "oracle = raw_df[\"LCA_CASE_EMPLOYER_NAME\"]==\"ORACLE AMERICA INC\"\n",
    "\n",
    "print \"Unique TOTAL_WORKERS values from Oracle:\", raw_df[\"TOTAL_WORKERS\"][oracle].unique()\n",
    "\n",
    "print \"Total applications from Oracle:\", raw_df[\"TOTAL_WORKERS\"][oracle].count()\n",
    "\n",
    "print \"Total applications from Oracle where TOTAL_WORKERS == 20:\",\\\n",
    "                raw_df[\"TOTAL_WORKERS\"][oracle][raw_df[\"TOTAL_WORKERS\"]==20].count()\n",
    "    \n",
    "print \"Total applications from Oracle where TOTAL_WORKERS == 100:\",\\\n",
    "                raw_df[\"TOTAL_WORKERS\"][oracle][raw_df[\"TOTAL_WORKERS\"]==100].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So TOTAL_WORKERS isn't an accurate metric, which is good to know. Going forward, I won't use this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_df = raw_df.drop(\"TOTAL_WORKERS\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I'm ready to write this dataframe to a csv. There are some non-ASCII characters here, so I'll need to set the encoding to utf-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_df.to_csv(\"Prepped_LCA.csv\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
